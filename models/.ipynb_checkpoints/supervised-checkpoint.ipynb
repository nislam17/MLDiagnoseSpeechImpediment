{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'../data/childrenDiagnosis.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-07fa8e64d10a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Read the file into a pandas data frame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/childrenDiagnosis.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelim_whitespace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mna_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m ''' columns = ['Y', 'filename', 'sex', 'age', 'age_years', 'corpus', 'group',\n\u001b[0;32m      4\u001b[0m        \u001b[1;34m'child_TNW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'child_TNS'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'examiner_TNW'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'freq_ttr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r_2_i_verbs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m        \u001b[1;34m'mor_words'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'num_pos_tags'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_dos'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'repetition'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'retracing'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    762\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 764\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    765\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    983\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3.6\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'../data/childrenDiagnosis.csv' does not exist"
     ]
    }
   ],
   "source": [
    "# Read the file into a pandas data frame.\n",
    "df = pd.read_csv(\"../data/childrenDiagnosis.csv\", header=0, delim_whitespace=False,na_values='?') \n",
    "''' columns = ['Y', 'filename', 'sex', 'age', 'age_years', 'corpus', 'group',\n",
    "       'child_TNW', 'child_TNS', 'examiner_TNW', 'freq_ttr', 'r_2_i_verbs',\n",
    "       'mor_words', 'num_pos_tags', 'n_dos', 'repetition', 'retracing',\n",
    "       'fillers', 's_1g_ppl', 's_2g_ppl', 's_3g_ppl', 'd_1g_ppl',\n",
    "       'd_2g_ppl', 'd_3g_ppl', 'z_mlu_sli', 'z_mlu_td',\n",
    "       'z_word_errors_sli', 'z_word_errors_td', 'z_r_2_i_verbs_sli',\n",
    "       'z_r_2_i_verbs_td', 'z_utts_sli', 'z_utts_td', 'total_syl',\n",
    "       'average_syl', 'mlu_words', 'mlu_morphemes', 'mlu100_utts',\n",
    "       'verb_utt', 'dss', 'ipsyn_total', 'present_progressive',\n",
    "       'propositions_in', 'propositions_on', 'plural_s',\n",
    "       'irregular_past_tense', 'possessive_s', 'uncontractible_copula',\n",
    "       'articles', 'regular_past_ed', 'regular_3rd_person_s',\n",
    "       'irregular_3rd_person', 'uncontractible_aux', 'contractible_copula',\n",
    "       'contractible_aux', 'word_errors', 'f_k', 'n_v', 'n_aux', 'n_3s_v',\n",
    "       'det_n_pl', 'det_pl_n', 'pro_aux', 'pro_3s_v', 'total_error'] \n",
    "  '''\n",
    "df1 = pd.DataFrame(df, columns=['Y', 'age_years',\n",
    "       'child_TNW', 'child_TNS', 'examiner_TNW', 'freq_ttr', 'r_2_i_verbs',\n",
    "       'mor_words', 'num_pos_tags', 'n_dos', 'repetition', 'retracing',\n",
    "       'fillers', 's_1g_ppl', 's_2g_ppl', 's_3g_ppl', 'd_1g_ppl',\n",
    "       'd_2g_ppl', 'd_3g_ppl', 'z_mlu_sli', 'z_mlu_td',\n",
    "       'z_word_errors_sli', 'z_word_errors_td', 'z_r_2_i_verbs_sli',\n",
    "       'z_r_2_i_verbs_td', 'z_utts_sli', 'z_utts_td', 'total_syl',\n",
    "       'average_syl', 'mlu_words', 'mlu_morphemes', 'mlu100_utts',\n",
    "       'verb_utt', 'dss', 'ipsyn_total', 'present_progressive',\n",
    "       'propositions_in', 'propositions_on', 'plural_s',\n",
    "       'irregular_past_tense', 'possessive_s', 'uncontractible_copula',\n",
    "       'articles', 'regular_past_ed', 'regular_3rd_person_s',\n",
    "       'irregular_3rd_person', 'uncontractible_aux', 'contractible_copula',\n",
    "       'contractible_aux', 'word_errors', 'f_k', 'n_v', 'n_aux', 'n_3s_v',\n",
    "       'det_n_pl', 'det_pl_n', 'pro_aux', 'pro_3s_v', 'total_error'])\n",
    "df1.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Shuffle rows and convert all data type to float\n",
    "df2 = np.array(df1.sample(frac=1).astype('float', copy=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df2[:, 1:]\n",
    "y = df2[:, 0]\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-aa119351ae3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(X[0])):\n",
    "    for j in range(i+1, len(X[0])):\n",
    "        plt.scatter(X[:, i], X[:, j], c=y)\n",
    "        plt.xlabel(df1.columns.values[i+1])\n",
    "        plt.ylabel(df1.columns.values[j+1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "X_new = SelectKBest(f_classif, k=46).fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test data.\n",
    "# Select first 600 rows as training dataset and the remaining rows as test dataset.\n",
    "X_train = X_new[:600, :]\n",
    "Y_train = y[:600]\n",
    "X_test = X_new[600:, :]\n",
    "Y_test = y[600:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Using Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_svm_linear = []\n",
    "acc_test_svm_linear = []\n",
    "c_svm_linear = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_linear(c):\n",
    "    # Create an object of svm.SVC(probability = False, kernel = 'linear', C = c).\n",
    "    svc = svm.SVC(probability = False, kernel = 'linear', C=c)\n",
    "    # Fit the classifier on the training set.\n",
    "    svc.fit(X_train, Y_train)\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_linear_train = svc.predict(X_train)\n",
    "    acc_train = np.mean(Yhat_svc_linear_train == Y_train)\n",
    "    acc_train_svm_linear.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_linear_test = svc.predict(X_test)\n",
    "    acc_test = np.mean(Yhat_svc_linear_test == Y_test)\n",
    "    acc_test_svm_linear.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc_test))\n",
    "    \n",
    "    c_svm_linear.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.845000\n",
      "Accuracy = 0.840142\n"
     ]
    }
   ],
   "source": [
    "svm_linear(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Radial Basis Function(RBF) Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_rbf(c, g):\n",
    "    # Create an object of svm classifier using svm.SVC()\n",
    "    # Pass probability = False, kernel = 'rbf', value of C = c and rbf paramter gamma = g.\n",
    "    svc_rbf = svm.SVC(probability = False, kernel='rbf', C=c, gamma=g)\n",
    "    # Fit the classifier on the training set.\n",
    "    svc_rbf.fit(X_train, Y_train)\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_rbf_train = svc_rbf.predict(X_train)\n",
    "    acc = np.mean(Yhat_svc_rbf_train == Y_train)\n",
    "    print('Accuracy = {0:f}'.format(acc))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_rbf_test = svc_rbf.predict(X_test)\n",
    "    acc = np.mean(Yhat_svc_rbf_test == Y_test)\n",
    "    print('Accuracy = {0:f}'.format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.765000\n",
      "Accuracy = 0.776199\n"
     ]
    }
   ],
   "source": [
    "svm_rbf(0.1, 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM using Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_svm_poly = []\n",
    "acc_test_svm_poly = []\n",
    "c_svm_poly = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def svm_polynomial(c):\n",
    "    # Create an object of svm classifier using svm.SVC()\n",
    "    # Pass probability = False, kernel = 'poly' , value of C = c.\n",
    "    svc_polynomial = svm.SVC(probability = False, kernel='poly', C=c)\n",
    "    A = X_train[0:300,:]  # First 300 rows of training set.\n",
    "    B = Y_train[0:300]  \n",
    "    C = X_test[0:100,:]   # First 100 rows of test set.\n",
    "    D = Y_test[0:100]\n",
    "    \n",
    "    # Fit the classifier on the training set.\n",
    "    # Use A and B to train and C and D to test.\n",
    "    svc_polynomial.fit(A, B)\n",
    "    \n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_svc_polynomial_train = svc_polynomial.predict(A)\n",
    "    acc_train = np.mean(Yhat_svc_polynomial_train == B)\n",
    "    acc_train_svm_poly.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc_train))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_svc_polynomial_test = svc_polynomial.predict(C)\n",
    "    acc_test = np.mean(Yhat_svc_polynomial_test == D)\n",
    "    acc_test_svm_poly.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc_test))\n",
    "    \n",
    "    c_svm_poly.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.993333\n",
      "Accuracy = 0.750000\n"
     ]
    }
   ],
   "source": [
    "svm_polynomial(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_train_nn = []\n",
    "acc_test_nn = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mlpclassifier(a):\n",
    "    mlp = MLPClassifier(solver='lbfgs', alpha=a, hidden_layer_sizes=(5, 2), random_state=1)\n",
    "    mlp.fit(X_train, Y_train)\n",
    "\n",
    "    # Find the prediction and accuracy on the training set.\n",
    "    Yhat_nn_train = mlp.predict(X_train)\n",
    "    acc_train = np.mean(Yhat_nn_train == Y_train)\n",
    "    acc_train_nn.append(acc_train)\n",
    "    print('Accuracy = {0:f}'.format(acc))\n",
    "    \n",
    "    # Find the prediction and accuracy on the test set.\n",
    "    Yhat_nn_test = mlp.predict(X_test)\n",
    "    acc_test = np.mean(Yhat_nn_test == Y_test)\n",
    "    acc_test_nn.append(acc_test)\n",
    "    print('Accuracy = {0:f}'.format(acc))\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
